# Artificial Intelligence (AI)

## Brief History

History of AI is discussed in the book... but we are not going to concern ourselves with that too much here.

It talks about, initially, how AI kinda started in the mid 1940s
with the neuron model proposed by Warren McCulloch and Walter Pitts.

Much of it goes over early iteration of attempts at making an AI model.

Most of these were small scale attempts which looked to solve **microworld** problems, that is, a specific small domain
of problems. For instance, one of an AI called **Analogy** which solved geometry problems.

One important thing to know from the history is the **Turing Test** proposed by Alan Turing in the year 1950.
The test is basically just has a participant determine if they are speaking to a machine or another person during a conversation and
helps us understand how close a machine has come to imitate the ability to think.

Beginning around 2001 1, large data sets became available to train AI on, and in 2017, 
Google developed a Large Language Model, which
is what we see today referred to as AI.


OpenAI's LLM is ChatGPT, which was released in 2022.

--------------------------------

## Basics

> **AI (Artificial Intelligen)**: The development and use of algorithms and models to mimic human thought.

These tools can be helpful in a numbers of areas. For instance, we can train an AI model to be able to recognize an animal
from an image, and have it scan through a billion images for us looking for an animal. Long, annoying tasks
can be easily simplified by a machine, like they have always done in the past.

When we talk about AI, it kinda covers a pretty general area. Like, technically, a series of 100 if/elif/else
statements can be considered "AI" if it does an "okay" job in acting like a human (even a dumb one).

But, the books lays out a few specific areas where AI is a part of it, by definition:

- **Machine Learning**: uses algorithms and models to amke predictions and discover patterns in data
- **Computer Vision**: uses algorithms and models to extract meaning from images and video
- **Natural Language processing**: uses algorithms and models to
- **Knowledge Representation**: is a framework for representing how knowledge is stored and processed
- **Automated Reasoning**: uses algorithms to reason or solve conceptual problems, such as proofs
- **Robotics**: is the design, construction, operation, and programming of robots

Now, it can be helpful in these areas, but it is not all sunshine and rainbows.


## GenAI aka Generative Artificial Intelligence aka Generative AI

These are algorithms and models which create content based on patterns learned from training data. 

The previously discussed models classify the data given to it, but generative AI instead tries to replicate the
data it has as input. 

This can be pictures, audio or text.

Think your DALLE, ChatGPT, or like the many, many generative AI audio apps.


## LLM

Large language models are models which have the ability to "understand", analyze, and generate human-like context.

Large language models enable what's known as Natural Language Processing (NLP) tasks. This is like answering questions, translating text,
summarizing text.

This is like ChatGPT

This is an example of a generative artificial intelligence, and is in fact an example of most of the subsets we have talked about.


Large Language Models are an example of Generative AI;
Generative AI is an example of Deep Learning;
Deep Learning is an example of machine learning;
machine learning is an example of AI.


## AI Ethics and Downsides

So, AI has some uses... but it has been shown to have some more downsides... ethical ones:

There are some downsides to having these AI models do literally everything though.

- it can make them sad :(
- there is privacy concerns with training AI... as in **Copyright Infringement**
  - AI needs data to train. Companies seem to be unbothered by whose data it is using to train these AI models and even if it is copyrighted work of individuals/artists. They are essentially stealing data/art to endlessly reproduce the style and likeness of it forever... and without giving credit to the original person.
- **Hallucinations**
  - Just like humans, the things being created can have mistakes. Typically, we expect machines to work perfectly, but these AI models do not (and will not). When an AI makes a mistake, it often sounds confident (that is, if it is an LLM) and it can be just wrong. Normally, if you are looking for answer for something, you would research as much as you can, draw from your current knowledge, consult experts, do experiments, and come to a conclusion. This obviously takes some logic... which some AI models simply do not have built in.
  - For instance, if you ask LARGE LANGUAGE MODEL about a fact, it can draw from it's database to see how maybe that answer was answered before... but maybe it pulled its info from a crazy website. It wouldn't know to not trust it or have the context of reality to help inform it, and therefore just gives you answer.
  - AI Fake Cases https://www.pcmag.com/news/attorney-slapped-with-hefty-fine-for-citing-21-fake-ai-generated-cases
  - Making up imports for code that does not exist
- Always Positive
  - Models like ChatGPT are kinda coded to always be encouraging and positive... even in the worst cases.
  - Even when people have had very negative thoughts (see below), AI still was encouraging them through it and basically helped them "logic" to doing horribly, sad things
  - https://www.timesfreepress.com/news/2025/nov/07/openai-faces-7-lawsuits-claiming-chatgpt-drove-people-to-suicide-delusions/
- Algorithmic Bias and Discrimination
  - Depending on what the input was that the AI model was trained on, it can be biased towards using that sort of info for its output, specifically for generative AI
  - For instance, due to some algorithmic discrimination, a healthcare algorithm found that black patients are more likely to be assigned as "low risk" by AI breast cancer predictors, resulting in potential miss of breast cancer diagnosis 
  - https://www.nature.com/articles/s41746-023-00858-z
- Deepfakes
  - These are videos/audio/pictures of real people created using generative AI which is normally done without their consent
  - These can show them doing embarrassing/ethically dubious activities
- Regulations
  - Due to some reason, there seems to be a huge lack of regulations being put into action 




## Future of AI



AI could eventually achieve what's known as Artificial Super Intelligence (ASI). This is where AI surpasses all of human intelligence, including knowledge,
creativity, and emotional intelligence.


## My thoughts

So I don't really think AI is going to take over the world and all that.

If that is the case, womp womp!

Otherwise, right now it seems to be a bubble:
- https://gizmodo.com/yet-another-study-shows-that-most-companies-arent-making-any-money-off-ai-2000688655

Right now, massive companies are going to utilize in both an attempt to not pay employees and instead use AI
and also advertise their use of AI as a selling point to potential shareholders.

So, at this moment, the use of AI is being inserted into everything, until eventually, the bubble pops.

Once this happens, most unnecessary uses of AI are going to probably be shut down, with the few remaining tools actually
find their place in the world.

Like ChatGPT will probably still be around, but like, just be used as a tool and HOPEFULLY not as an investment monster thing.

